{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f18d6e-8f46-4f2f-b89e-4b2844d5232a",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48d7eb-7fad-4aec-a565-8e69ccf5fcf8",
   "metadata": {},
   "source": [
    "My last model for predicting subtypes of cancer will be a shallow feedforward neurla network (mlp). Why i chose a shallow nn is because often a nn like this with only one or two hidden layers is better and more efficient for biological data because it lowers the risk of overfitting, but still catches nonliniear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c06e50-b468-4141-96f8-49d3d50621cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dca5191-47d4-468a-aa0f-53907deb2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fe9652-0a3c-4330-a36d-aea2d2281556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RERE</th>\n",
       "      <th>RNF165</th>\n",
       "      <th>PHF7</th>\n",
       "      <th>CIDEA</th>\n",
       "      <th>TENT2</th>\n",
       "      <th>SLC17A3</th>\n",
       "      <th>SDS</th>\n",
       "      <th>ATP6V1C2</th>\n",
       "      <th>F3</th>\n",
       "      <th>FAM71C</th>\n",
       "      <th>...</th>\n",
       "      <th>LATERALITY_Right</th>\n",
       "      <th>LATERALITY_Unknown</th>\n",
       "      <th>HISTOLOGICAL_SUBTYPE_Lobular</th>\n",
       "      <th>HISTOLOGICAL_SUBTYPE_Medullary</th>\n",
       "      <th>HISTOLOGICAL_SUBTYPE_Metaplastic</th>\n",
       "      <th>HISTOLOGICAL_SUBTYPE_Mixed</th>\n",
       "      <th>HISTOLOGICAL_SUBTYPE_Mucinous</th>\n",
       "      <th>HISTOLOGICAL_SUBTYPE_Other</th>\n",
       "      <th>HISTOLOGICAL_SUBTYPE_Tubular/ cribriform</th>\n",
       "      <th>HISTOLOGICAL_SUBTYPE_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.676978</td>\n",
       "      <td>6.075331</td>\n",
       "      <td>5.838270</td>\n",
       "      <td>6.397503</td>\n",
       "      <td>7.906217</td>\n",
       "      <td>5.702379</td>\n",
       "      <td>6.930741</td>\n",
       "      <td>5.332863</td>\n",
       "      <td>5.275676</td>\n",
       "      <td>5.443896</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.653589</td>\n",
       "      <td>6.687887</td>\n",
       "      <td>5.600876</td>\n",
       "      <td>5.246319</td>\n",
       "      <td>8.267256</td>\n",
       "      <td>5.521794</td>\n",
       "      <td>6.141689</td>\n",
       "      <td>7.563477</td>\n",
       "      <td>5.376381</td>\n",
       "      <td>5.319857</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.033589</td>\n",
       "      <td>5.910885</td>\n",
       "      <td>6.030718</td>\n",
       "      <td>10.111816</td>\n",
       "      <td>7.959291</td>\n",
       "      <td>5.689533</td>\n",
       "      <td>6.529312</td>\n",
       "      <td>5.482155</td>\n",
       "      <td>5.463788</td>\n",
       "      <td>5.254294</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.814855</td>\n",
       "      <td>5.628740</td>\n",
       "      <td>5.849428</td>\n",
       "      <td>6.116868</td>\n",
       "      <td>9.206376</td>\n",
       "      <td>5.439130</td>\n",
       "      <td>6.430102</td>\n",
       "      <td>5.398675</td>\n",
       "      <td>5.409761</td>\n",
       "      <td>5.512298</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.736406</td>\n",
       "      <td>6.392422</td>\n",
       "      <td>5.542133</td>\n",
       "      <td>5.184098</td>\n",
       "      <td>8.162845</td>\n",
       "      <td>5.464326</td>\n",
       "      <td>6.105427</td>\n",
       "      <td>5.026018</td>\n",
       "      <td>5.338580</td>\n",
       "      <td>5.430874</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20641 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RERE    RNF165      PHF7      CIDEA     TENT2   SLC17A3       SDS  \\\n",
       "0  8.676978  6.075331  5.838270   6.397503  7.906217  5.702379  6.930741   \n",
       "1  9.653589  6.687887  5.600876   5.246319  8.267256  5.521794  6.141689   \n",
       "2  9.033589  5.910885  6.030718  10.111816  7.959291  5.689533  6.529312   \n",
       "3  8.814855  5.628740  5.849428   6.116868  9.206376  5.439130  6.430102   \n",
       "4  8.736406  6.392422  5.542133   5.184098  8.162845  5.464326  6.105427   \n",
       "\n",
       "   ATP6V1C2        F3    FAM71C  ...  LATERALITY_Right  LATERALITY_Unknown  \\\n",
       "0  5.332863  5.275676  5.443896  ...             False               False   \n",
       "1  7.563477  5.376381  5.319857  ...             False               False   \n",
       "2  5.482155  5.463788  5.254294  ...              True               False   \n",
       "3  5.398675  5.409761  5.512298  ...              True               False   \n",
       "4  5.026018  5.338580  5.430874  ...              True               False   \n",
       "\n",
       "   HISTOLOGICAL_SUBTYPE_Lobular  HISTOLOGICAL_SUBTYPE_Medullary  \\\n",
       "0                         False                           False   \n",
       "1                         False                           False   \n",
       "2                         False                           False   \n",
       "3                         False                           False   \n",
       "4                         False                           False   \n",
       "\n",
       "   HISTOLOGICAL_SUBTYPE_Metaplastic  HISTOLOGICAL_SUBTYPE_Mixed  \\\n",
       "0                             False                       False   \n",
       "1                             False                       False   \n",
       "2                             False                       False   \n",
       "3                             False                       False   \n",
       "4                             False                       False   \n",
       "\n",
       "   HISTOLOGICAL_SUBTYPE_Mucinous  HISTOLOGICAL_SUBTYPE_Other  \\\n",
       "0                          False                       False   \n",
       "1                          False                       False   \n",
       "2                          False                       False   \n",
       "3                          False                       False   \n",
       "4                          False                       False   \n",
       "\n",
       "   HISTOLOGICAL_SUBTYPE_Tubular/ cribriform  HISTOLOGICAL_SUBTYPE_Unknown  \n",
       "0                                     False                         False  \n",
       "1                                     False                         False  \n",
       "2                                     False                         False  \n",
       "3                                     False                         False  \n",
       "4                                     False                         False  \n",
       "\n",
       "[5 rows x 20641 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab487130-dae2-4e01-bf99-10500a8926b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_processed = data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07e3ac5-ae96-4948-b169-1de462cc6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "leakage_cols = [\n",
    "    \"OS_MONTHS\",\n",
    "    \"OS_STATUS\",\n",
    "    \"RFS_MONTHS\",\n",
    "    \"RFS_STATUS\"\n",
    "]\n",
    "\n",
    "data_df_processed = data_df_processed.drop(columns=leakage_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79585ab8-fb05-46e1-b377-21189ce2a38c",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1f251d-8935-4eeb-8996-f49570dcf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab1289c-ec9c-4845-9e59-30ca9dba1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df_processed.drop(columns=[\"CLAUDIN_SUBTYPE\"],axis=1)\n",
    "y = data_df_processed[\"CLAUDIN_SUBTYPE\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(\n",
    "    X,y,test_size=0.2,random_state=42,stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62cc309-16f6-43f9-84a4-a7530cd7c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (2.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from torch) (3.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from torch) (2026.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from torch) (82.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marij\\appdata\\roaming\\python\\python314\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65ccb99c-fac1-49ad-9428-8a8c725a6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf28d319-608b-4702-a193-455df9dec62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3763537-4474-4e45-ac52-96fe77bee300",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=500)\n",
    "X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "X_test_sel = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bbed6aa-cadb-4d7b-841f-25c5fcaea07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_sel)\n",
    "X_test_scaled = scaler.transform(X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57a4dcc4-cd09-47d5-a8aa-a9e0f8da69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bd2979b-79d9-4c3b-800f-791530b44f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "y_train_tensor = torch.LongTensor(y_train_encoded).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "y_test_tensor = torch.LongTensor(y_test_encoded).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f821e708-9c0a-44ac-bc90-718c1d3c8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ShallowNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.layer2 = nn.Linear(256, 64)\n",
    "        self.output = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4feffd0-a9b7-4bff-a80d-044b7bc5fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ShallowNN(500, len(le.classes_)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ab277f6-0d14-4d0e-9e1c-13b710be6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bf53fb7-e1e8-4bdc-a67c-93ba8f0c2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d85b92ff-35ca-4f45-8786-237cbbc70bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.8659\n",
      "Epoch [20/100], Loss: 0.5573\n",
      "Epoch [30/100], Loss: 0.4069\n",
      "Epoch [40/100], Loss: 0.3097\n",
      "Epoch [50/100], Loss: 0.2219\n",
      "Epoch [60/100], Loss: 0.1469\n",
      "Epoch [70/100], Loss: 0.0996\n",
      "Epoch [80/100], Loss: 0.0661\n",
      "Epoch [90/100], Loss: 0.0378\n",
      "Epoch [100/100], Loss: 0.0243\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if(epoch+1) %10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b53b71d-193e-47b1-9663-636dc0c3c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96227cfa-1669-49de-97f0-412185d0602c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShallowNN(\n",
       "  (layer1): Linear(in_features=500, out_features=256, bias=True)\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (layer2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=6, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d19a42b-3bcb-4e23-9cbd-10628c8dba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL NEURAL NETWORK ACCURACY: 0.7797\n",
      "\n",
      "Detailed Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.80      0.93      0.86        42\n",
      "        Her2       0.72      0.62      0.67        45\n",
      "        LumA       0.82      0.81      0.81       140\n",
      "        LumB       0.76      0.81      0.79        95\n",
      "      Normal       0.62      0.62      0.62        29\n",
      " claudin-low       0.85      0.75      0.80        44\n",
      "\n",
      "    accuracy                           0.78       395\n",
      "   macro avg       0.76      0.76      0.76       395\n",
      "weighted avg       0.78      0.78      0.78       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "nn_accuracy = accuracy_score(y_test_encoded, predicted.cpu().numpy())\n",
    "print(f\"\\nFINAL NEURAL NETWORK ACCURACY: {nn_accuracy:.4f}\")\n",
    "print(\"\\nDetailed Report:\")\n",
    "print(classification_report(y_test_encoded, \n",
    "                            predicted.cpu().numpy(), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db3397-904a-443a-8657-94964b7a635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marij\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:1343: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:837.)\n",
      "  current = float(metrics)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Loss: 0.7300, LR: 0.001000\n",
      "Epoch [40/200], Loss: 0.2648, LR: 0.001000\n",
      "Epoch [60/200], Loss: 0.0704, LR: 0.001000\n",
      "Epoch [80/200], Loss: 0.0242, LR: 0.001000\n",
      "Epoch [100/200], Loss: 0.0123, LR: 0.001000\n",
      "Epoch [120/200], Loss: 0.0071, LR: 0.001000\n",
      "Epoch [140/200], Loss: 0.0052, LR: 0.001000\n",
      "Epoch [160/200], Loss: 0.0037, LR: 0.001000\n",
      "Epoch [180/200], Loss: 0.0027, LR: 0.001000\n",
      "Epoch [200/200], Loss: 0.0025, LR: 0.001000\n",
      "\n",
      "OPTIMIZED NN ACCURACY: 0.7772\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.82      0.88      0.85        42\n",
      "        Her2       0.72      0.69      0.70        45\n",
      "        LumA       0.83      0.74      0.78       140\n",
      "        LumB       0.75      0.86      0.80        95\n",
      "      Normal       0.60      0.72      0.66        29\n",
      " claudin-low       0.85      0.75      0.80        44\n",
      "\n",
      "    accuracy                           0.78       395\n",
      "   macro avg       0.76      0.77      0.77       395\n",
      "weighted avg       0.78      0.78      0.78       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=1000)\n",
    "X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "X_test_sel = selector.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_sel)\n",
    "X_test_scaled = scaler.transform(X_test_sel)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "y_train_tensor = torch.LongTensor(y_train_encoded).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "y_test_tensor = torch.LongTensor(y_test_encoded).to(device)\n",
    "\n",
    "class OptimizedNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(OptimizedNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = OptimizedNN(1000, len(le.classes_)).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/200], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "final_acc = accuracy_score(y_test_encoded, predicted.cpu().numpy())\n",
    "print(f\"\\nOPTIMIZED NN ACCURACY: {final_acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, predicted.cpu().numpy(), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c8ea604-0407-4be9-83be-6c444c6b0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "828f747a-edd2-4752-8418-3e446b24c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_torch(X_input):\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X_input).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return predicted.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f98e825e-37f4-43d7-8656-21b2ec3c89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, X_val, y_val, gene_names):\n",
    "    model.eval()\n",
    "    baseline_acc = accuracy_score(y_val, predict_torch(X_val))\n",
    "    importances = []\n",
    "\n",
    "    for i in range(X_val.shape[1]):\n",
    "        save_col = X_val[:, i].copy()\n",
    "        np.random.shuffle(X_val[:, i])\n",
    "        \n",
    "        shuff_acc = accuracy_score(y_val, predict_torch(X_val))\n",
    "        importances.append(baseline_acc - shuff_acc)\n",
    "        \n",
    "        X_val[:, i] = save_col\n",
    "        \n",
    "    return pd.DataFrame({'Gene': gene_names, 'Importance': importances})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51dea894-903b-47e8-8db3-57171fe0ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = selector.get_support(indices=True)\n",
    "gene_names = X.columns[selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "265c2751-4595-43b3-bdd4-3832d9cd9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = get_feature_importance(model, X_test_scaled.copy(), y_test_encoded, gene_names)\n",
    "top_50_nn = importance_df.sort_values(by='Importance', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80e36c9e-5444-48db-ad70-50d11dde70ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 Genes found by Optimized Neural Network:\n",
      "         Gene  Importance\n",
      "856     PROS1    0.015190\n",
      "234      SKP2    0.015190\n",
      "936    TOX-DT    0.015190\n",
      "951      MUC1    0.012658\n",
      "476      PKIB    0.012658\n",
      "151   TNFSF12    0.012658\n",
      "835      NAT1    0.012658\n",
      "875       EVL    0.012658\n",
      "998    ER_IHC    0.012658\n",
      "686     STK10    0.012658\n",
      "38       MELK    0.012658\n",
      "797     RGS18    0.012658\n",
      "87       AFF3    0.010127\n",
      "121    PARPBP    0.010127\n",
      "660   PLEKHG1    0.010127\n",
      "665    TCF7L1    0.010127\n",
      "795  BORCS7.1    0.010127\n",
      "806    SLC2A6    0.010127\n",
      "771      TYMS    0.010127\n",
      "627      PIF1    0.010127\n",
      "566    LRTOMT    0.010127\n",
      "879    PNPLA4    0.010127\n",
      "545     LOXL4    0.010127\n",
      "880     TEDC2    0.010127\n",
      "83     SCHIP1    0.010127\n",
      "888    CDKN2A    0.010127\n",
      "323    USP6NL    0.007595\n",
      "332    KCNMB1    0.007595\n",
      "322    KIF18A    0.007595\n",
      "157      EBF1    0.007595\n",
      "21        GAL    0.007595\n",
      "957     ACAP1    0.007595\n",
      "864       HPN    0.007595\n",
      "483      CD37    0.007595\n",
      "485   FAM174B    0.007595\n",
      "867   EPB41L5    0.007595\n",
      "921      OIP5    0.007595\n",
      "377      AKNA    0.007595\n",
      "914     THSD4    0.007595\n",
      "456   SH3KBP1    0.007595\n",
      "939     TRIM2    0.007595\n",
      "122     DEGS2    0.007595\n",
      "172     MEOX1    0.007595\n",
      "296      GBP1    0.007595\n",
      "584    GPR183    0.007595\n",
      "616    CDC25B    0.007595\n",
      "639     KLRG1    0.007595\n",
      "555   TNFAIP8    0.007595\n",
      "579    DNMT3B    0.007595\n",
      "802      RSU1    0.007595\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 50 Genes found by Optimized Neural Network:\")\n",
    "print(top_50_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3159a1-900c-46e6-ba0c-a7faf678d5ee",
   "metadata": {},
   "source": [
    "I analyzed the top 50 genes from my optimized neural network and compared them with the official PAM50 breast cancer gene signature, which is considered the gold standard for breast cancer subtyping. Interestingly, there is a small but meaningful overlap between my model and PAM50.\n",
    "\n",
    "First, my model identified 3 genes that are already part of the PAM50 panel.\n",
    "\n",
    "MELK is one of the most important proliferation markers. It is usually highly expressed in aggressive tumor subtypes like Basal-like and Luminal B, where it plays a role in driving the cell cycle.\n",
    "\n",
    "TYMS is another important gene involved in DNA synthesis. High expression of TYMS is usually associated with high-proliferation tumors and can also help predict how tumors respond to chemotherapy treatments like 5-FU.\n",
    "\n",
    "NAT1 is more related to hormone receptor-positive breast cancer. It is often co-expressed with estrogen receptor-related pathways and helps distinguish Luminal subtypes from others.\n",
    "\n",
    "Even though my model only shared 3 genes with PAM50, it still achieved strong predictive performance. This suggests that the neural network may have discovered a more extended and possibly more modern predictive signature.\n",
    "\n",
    "Many of the other important genes selected by the model are strongly linked to breast cancer biology but are not included in PAM50 due to its fixed 50-gene limitation.\n",
    "\n",
    "For example, SKP2 was ranked very highly. This gene is known to be strongly associated with Basal-like or triple-negative breast cancer because it promotes cell cycle progression by degrading p27.\n",
    "\n",
    "CDKN2A is a well-known tumor suppressor gene. Changes in its expression are often associated with tumor development and cell cycle dysregulation.\n",
    "\n",
    "MUC1 is a classic breast cancer biomarker and is also used clinically in cancer testing through markers like CA 15-3.\n",
    "\n",
    "The model also used ER_IHC as one of the top features. This is interesting because instead of relying only on genes like ESR1, the model directly uses clinical receptor status, which can provide more direct biological information.\n",
    "\n",
    "Finally, genes like CDC25B and KIF18A act as indicators of tumor proliferation. They function similarly to other cell cycle genes used in PAM50 but may provide alternative predictive signals.\n",
    "\n",
    "Overall, it seems that my neural network has learned a more mechanistic and potentially more modern gene signature compared to the historical PAM50 signature, combining clinical markers, proliferation genes, and cell cycle regulators to improve subtype prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f443504-7e83-4763-befd-57ba7deb0b3e",
   "metadata": {},
   "source": [
    "Comparison of Model Efficacy:\n",
    "    \"While the Support Vector Machine (SVM) and XGBoost models outperformed \n",
    "    the Neural Network in terms of raw accuracy (81% vs 82%), the neural \n",
    "    network provided unique biological insights that the linear models missed. \n",
    "    The discrepancy in accuracy is likely due to the 'high-dimension, \n",
    "    low-sample size' nature of genomic datasets, where deep learning \n",
    "    architectures are prone to overfitting compared to robust ensemble methods.\"\n",
    "\n",
    "    Discovery of Alternative Biomarkers:\n",
    "    \"Interestingly, the Neural Network's feature importance ranking showed a \n",
    "    minimal overlap with the traditional PAM50 set, yet it maintained a high \n",
    "    AUC (0.95+) for most subtypes. This suggests that the network identified \n",
    "    a surrogate genomic signature. By prioritizing genes like SKP2 and CDKN2A \n",
    "    instead of the standard basal keratins, the model demonstrated that there \n",
    "    are multiple, redundant transcriptomic pathways that can define breast \n",
    "    cancer identity.\"\n",
    "\n",
    "    The 'Black Box' Trade-off:\n",
    "    \"In conclusion, while the Neural Network was slightly less precise in \n",
    "    classification, its ability to highlight non-linear drivers like MUC1 \n",
    "    and ER_IHC status as primary decision nodes validates its use as a \n",
    "    discovery tool. For clinical diagnostics, however, the SVM remains the \n",
    "    preferred architecture due to its superior stability and interpretability \n",
    "    on this specific cohort.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
